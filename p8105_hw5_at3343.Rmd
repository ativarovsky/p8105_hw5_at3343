---
title: "Homework 5"
author: "Alice Tivarovsky"
date: "11/3/2019"
output: github_document
editor_options: 
  chunk_output_type: inline
---

## Setup Code

```{r setup, include=TRUE}

library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_bw() + theme(legend.position = "bottom"))

set.seed(10)
```

## Problem 1

Pulling in iris: 

```{r}

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))

iris_with_missing
```

Writing a function that fills in missing values:


```{r}
output = vector("list", length = 5)

# generate a logical vector, output
for (i in 1:5) {
  output[[i]] = is.numeric(iris_with_missing[[i]])
}
output

# if output = true, run a loop, calculating mean in each vector, then replacing blanks with the mean 

```


```{r}
output = vector("list", length = 5)

for (i in 1:5) {
  
  if (is.numeric(iris_with_missing[[i]])) {
    
    x = iris_with_missing[[i]] %>% mean(na.rm = TRUE)
    iris_with_missing[[i]] %>% replace(is.na(iris_with_missing[[i]]), x)
    
  } else if (is.character(iris_with_missing[[i]])) {
    iris_with_missing[[i]] %>% replace(is.na(iris_with_missing[[i]]), "virginica")
  }
  
}

```

Try defining a function: 

```{r}

iris_replace = function(x){
  
  if (is.numeric(x)) {
    y = mean(x, na.rm = TRUE)
    x = replace(x, is.na(x), y)
  } else if (is.character(x)) {
    x = replace(x, is.na(x), "virginica")
  }
}

```

Can do this with a for loop: 

```{r}
output = vector("list", length = 5)

for (i in 1:5) {
  
  output[[i]] = iris_replace(iris_with_missing[[i]])
  
}
output
```


Now, just with a map statement.

```{r}

output = map_df(iris_with_missing, iris_replace)

output
```


## Problem 2

Making dataframe with all file names. 

```{r}

files = list.files(path = "./data") 
files

```

Function that reads in data from vector "files" and saves the result as a new variable in the dataframe. 

```{r}

read_num2 = function(x){
  
  str_c("./data/", x) %>% 
    read_csv() %>% 
    pivot_longer(
      week_1:week_8,
      names_to = "week",
      names_prefix = "week_",
      values_to = "value"
      ) %>% 
    mutate("patient_id" = str_remove(x, ".csv"))
}

```

Map statement: 

```{r}

output = map_df(files, read_num2)

output
```

Make some updates to the data table. 

```{r}
df_num2 = 
  output %>% 
  mutate(
    arm = str_replace(patient_id, "_..", ""), 
    arm = as_factor(arm)
  ) %>% 
  select(
    patient_id, arm, week, value
  )

df_num2
```

Making spaghetti plot of df_num2. 

```{r}
df_num2 %>% 
  ggplot(aes(x = week, y = value)) + 
  geom_line(aes(group = patient_id, color = arm)) + 
   labs(
    title = "Study Value by Week",
    x = "Week",
    y = "Value"
   )
```

In the experiemntal arm, the values generally increase week over week. In the control arm, the values generally fluctuate around the same point without any observable upwards or downwards trend. 


## Problem 3

First the function: 

```{r}
n = 30
sd = sqrt(50)
beta_0 = 2


sim_slr = function(n, beta_0 = 2, beta_1 = 0) {
  
  sim_data = tibble(
    x_i1 = rnorm(n, 0, 1),
    y = beta_0 + beta_1*x_i1 + rnorm(n, 0, sd)
  )
  
ls_fit = lm(y ~ x_i1, data = sim_data) %>% broom::tidy() %>% filter(term == "x_i1") %>% select("estimate", "p.value") %>% rename(beta_1_hat = estimate)

}

```


Now running the simulation: 
 
```{r}

sim_results = 
  rerun(10000, sim_slr(n, beta_0 = 2, beta_1 = 0)) %>% 
  bind_rows() 

sim_results

```

Now re-running the simulation for beta_1 values (1, 2, 3, 4, 5). 

```{r}
sim_results_2 = 
  tibble(beta_1 = c(1:6)) %>% 
  mutate(
    output_list = map(.x = beta_1, ~rerun(10000, sim_slr(n, beta_0 = 2, beta_1 = .x))),
    estimate_list = map(output_list, bind_rows)) %>% 
  select(-output_list) %>% 
  unnest(estimate_list) 

sim_results_2
```

Plot of true beta_1 vs proportion of times that the null was rejected. 

```{r}
sim_results_plot = 
  sim_results_2 %>% 
  group_by(beta_1) %>% 
  summarise(n = n(), sig = sum(p.value < 0.05), prop = sig/n) %>% 
  ggplot(aes(x = beta_1, y = prop)) +
  geom_point() +
  labs(
    title = "Effect Size vs Power", 
    x = "Effect Size", 
    y = "Power"
  ) +
  scale_x_continuous(
    breaks = c(1:6),
    labels = c("1", "2", "3", "4", "5", "6")
  )

sim_results_plot

```

Based on the plot, as the effect size increases (i.e. as beta increases), the power also increases. The association does not quite appear to be linear, possibly logarithmic.  We note that the values for power are generally low, possibly owing to a small sample size. 

Going back to sim_results_2: 

```{r}
sim_results_2 %>% 
  group_by(beta_1) %>% 
  summarise(n = n(), beta_hat_mean = mean(beta_1_hat)) %>% 
  ggplot(aes(x = beta_1, y = beta_hat_mean)) +
  geom_point()
```

```{r}
sim_results_2 %>% 
  filter(p.value < 0.05) %>% 
  group_by(beta_1) %>% 
  summarise(n = n(), beta_hat_mean = mean(beta_1_hat)) %>% 
  ggplot(aes(x = beta_1, y = beta_hat_mean)) +
  geom_point()
```

